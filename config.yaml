# Config to train the Multilingual-Sign-Language-Translation model on the SP-10 dataset.
########################################################################################

name: mlslt
mode: train # train or test

pretrained_name: null # path to checkpoint. Mandatory for test mode.
resume_pretrained_state: false # Restore the optimizer and dataset configuration from the checkpoint. Used only when pretrained_name is given and mode is train.

model:
  enable_mapper: true # Enable the mapper module
  enable_resampler_xattn: true # Enable the resampler and the gated xattn module

  vision:
    pretrained_name: openai/clip-vit-base-patch32 # Pre-trained weights of the vision encoder found on huggingface
    trainable: false

  mapper:
    mapper_type: 'mlp' # Can be ['mlp', 'transformer']
    depth: 8 # Only for transformer
    heads: 8 # Only for transformer
    dim_feedforward: 2048 # Only for transformer
    mlp_dim: 512 # Only for mlp
    trainable: true

  resampler:
    depth: 6
    dim_head: 64
    heads: 8
    num_latents: 64
    num_time_embeds: 500
    ff_mult: 1
    activation: gelu
    trainable: true

  text:
    pretrained_name: gpt2 # Pre-trained weights of the text generator found on huggingface
    trainable: false
    trainable_lm_head: false
    xattn:
      dim_head: 64
      heads: 8
      num_latents: 64
      ff_mult: 1
      activation: gelu
      freq: 4

  optimizer:
    name: adamw # Optimizer to use for training. Can be ['adamw', 'adam']
    lr: 0.001
    betas: [0.9, 0.98]
    weight_decay: 1e-3

    # scheduler setup
    scheduler:
      name: CosineAnnealing # Can be ['CosineAnnealing', 'Linear']
      warmup_steps: null
      warmup_ratio: 0.1
      min_lr: 1e-6

dataset:
  # List of sign languages to use for training
  # Can be ['zh', 'uk', 'ru', 'bg', 'is', 'de', 'it', 'sv', 'lt', 'en']
  sign_languages: ['en']

  tokenizer: 'gpt2' # Can be either 'gpt2' or path to a json tokenizer file

  train_ds:
    video_dir: ???
    json_path: ???
    batch_size: 16
    num_workers: 4
    shuffle: true

  validation_ds:
    video_dir: ???
    json_path: ???
    batch_size: 16
    num_workers: 4
    shuffle: true

  test_ds: # Mandatory for test mode
    video_dir: ???
    json_path: ???

trainer:
  epochs: 40
  exp_dir: null
  exp_name: ${name}
  check_val_every_n_epoch: 1 # Check validation every n epochs
  test:
    decoding_strategy: beam # Can be ['greedy', 'nucleus', 'beam']
    max_length: 100
    temperature: 0.9
    top_p: 0.8 # Only for nucleus sampling
    top_k: null # Only for nucleus sampling
    beam_width: 5 # Only for beam search
  checkpoint_callback_params:
    monitor: val_loss # Can be ['train_loss', 'val_loss']
    save_top_k: 1

hydra:
  run:
    dir: ${trainer.exp_dir}/${trainer.exp_name}
  sweep:
    dir: ${hydra.run.dir}
    subdir: ${hydra.job.num}
